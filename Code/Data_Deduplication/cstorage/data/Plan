Secure Data Deduplication using SHA-3 and PSO on Cloud Storage System
=========================================================================
Implementation plan:
----------------------------------
Step 1: We create a cloud environment. 
 
Step 2: next we implement user register for new users.
 
Step 3: next implement user authentication .if valid user browse and give file 
 
Step 4: file divided into chunk (chunk size is not user define value fixed),here Divisor selection algorithm using Greatest Common Divisor (GCD) calculation 
 
Step 5: Each chunk file apply pre-prcess for File Tokenization,Binary Conversion and Compute words weight(TF-IDF)
 
Step 6: next implement Hash Computation for Decimal value using SHA-3.If hashes true duplicate file occur its not store else store the file into 	cloud storage

Step 7:we can reduce the data access time and retrieval is made easier for the data enquired. The particle swarm optimization (PSO) algorithm decides whether a block of data is new to the system. It is the first attempt when PSO is applied in the field cloud storage, which further improve the storage efficiency
 
Step 8: Data retrieved using users public key generated by ECC algorithm
 
Step 9: finally, plot the graph proposed work only for deduplication elimination ratio (DER), deduplication time, throughput.
 
==============================================================
s/w req:
-------------
1)jdk-1.8
2)netbeans-8.0
3)ubuntu-14.04 LTS
4)Xamp
